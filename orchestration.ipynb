{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python file serves as an orchestration program to be run **after** *civiActivityReport.ipynb*.\n",
    "Components:\n",
    "1. make copies of the two output tables from civiActivityReport.ipynb in order to standardize them for the proceeding stored procedures. \n",
    "**original name convention**: \n",
    "- mem_status_(2-digit mo, 2-digit day) ex. \"mem_status_0406\" \n",
    "- mem_type_(2-digit mo, 2-digit day); ex \"mem_type_0406\"\n",
    "\n",
    "    This is done in order to preserve the original import table names, which should be deleted manually later\n",
    "\n",
    "2. run ea stored procedure (*stored_procedure_create_type_tables*, *stored_procedure_create_status_table*), ea of which serve to insert new records (output from the new CIVI import processed by *civiActivityReport.ipynb*) into a new version of the cumulative type and status tables of the db; consolidated table names in db: consolidated_mem_type, consolidated_mem_status\n",
    "3. conduct QA on the new version of the two consolidated output tables from the stored procedure: *consolidated_mem_type_temp2* and *consolidated_mem_status_temp2*\n",
    "4. if QA from #3 passes, replace the two prod *consolidated* tables\n",
    "5. call the stored procedure to create the stack_job table: *stored_procedure_create_stack_job.sql*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import itertools\n",
    "import json\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to the 172.17.0.2 for user root created successfully.\n"
     ]
    }
   ],
   "source": [
    "# DEFINE THE DATABASE CREDENTIALS\n",
    "user = 'root'\n",
    "password = 'baeldung'\n",
    "host = '172.17.0.2'\n",
    "port = 3306\n",
    "database = 'membership'\n",
    "\n",
    "def get_connection():\n",
    "\treturn sqlalchemy.create_engine(\n",
    "\t\turl=\"mysql+pymysql://{0}:{1}@{2}:{3}/{4}\".format(\n",
    "\t\t\tuser, password, host, port, database\n",
    "\t\t)\n",
    "\t)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\ttry:\n",
    "\t\n",
    "\t\t# GET THE CONNECTION OBJECT (ENGINE) FOR THE DATABASE\n",
    "\t\t# working w/engines: https://docs.sqlalchemy.org/en/20/core/engines_connections.html\n",
    "\t\tengine = get_connection() #engine should be created just once, and can manage several DBAPI connections\n",
    "\t\tprint(\n",
    "\t\t\tf\"Connection to the {host} for user {user} created successfully.\")\n",
    "\texcept Exception as ex:\n",
    "\t\tprint(\"Connection could not be made due to the following error: \\n\", ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make copies of the two output tables from the .ipynb <- change table name to a generic name to be consumed by the stored procedures\n",
    "def copy_rename(type_table: str, status_table: str):\n",
    "    #a CORE approach\n",
    "    #type_table = 'mem_type_'\n",
    "    #status_table = 'mem_status_'\n",
    "    #want to limit the scope of the of our use of this object to a specific context, so we use Python's context manager \"with\"\n",
    "    with engine.connect() as conn: #interacting w/db through Connection class\n",
    "        conn.execute(sqlalchemy.text(\"DROP TABLE IF EXISTS mem_type_new_import\"))\n",
    "        conn.execute(sqlalchemy.text(f\"CREATE TABLE mem_type_new_import LIKE {type_table}\"))\n",
    "        conn.execute(sqlalchemy.text(f\"INSERT INTO mem_type_new_import SELECT * FROM {type_table}\"))\n",
    "\n",
    "        conn.execute(sqlalchemy.text(\"DROP TABLE IF EXISTS mem_status_new_import\"))\n",
    "        conn.execute(sqlalchemy.text(f\"CREATE TABLE mem_status_new_import LIKE {status_table}\"))\n",
    "        conn.execute(sqlalchemy.text(f\"INSERT INTO mem_status_new_import SELECT * FROM {status_table}\"))\n",
    "        #conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if I want to handle errors, the relative error category is \"programming-time error\"\n",
    "copy_rename('mem_type_0406','mem_status_0406')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all clear\n"
     ]
    }
   ],
   "source": [
    "#inspector option: https://docs.sqlalchemy.org/en/20/core/reflection.html#fine-grained-reflection-with-inspector\n",
    "# inspector is a low level interface which provides a backend-agnostic system of loading lists of schema, table, column, and constraint descriptions from a given database is also available.\n",
    "from sqlalchemy import inspect\n",
    "insp = inspect(engine)\n",
    "table_name_list = insp.get_table_names()\n",
    "#determine whether the tables I expect to have been injected into db from the civiActivityReport.ipynb are there\n",
    "if all([i in table_name_list for i in('mem_type_0406','mem_status_0406')]):\n",
    "    print('all clear to proceed')\n",
    "else:\n",
    "    print('new tables from copy_rename() step aren\\'t found in db')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run each stored procedure; first check that the stored procedure is stored on the db (query\" *show procedure status where definer LIKE '%root%';*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GetStudentData', 'status_table_create', 'table_creations', 'typetablecreate', 'type_table_create']\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(sqlalchemy.text(\"show procedure status where definer LIKE '%root%'\"))\n",
    "    lista = [i[1] for i in result.all()]\n",
    "\n",
    "print(lista)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "#a Core approach (because I'm interacting explicitly w/the engine as opposed to abstracted objects), where I write explicit SQL code\n",
    "if all([i in lista for i in ['status_table_create', 'type_table_create']]):\n",
    "    #copied code from https://docs.sqlalchemy.org/en/20/core/connections.html\n",
    "    connection = engine.raw_connection()\n",
    "    try:\n",
    "        cursor_obj = connection.cursor()\n",
    "        cursor_obj.callproc(\"type_table_create\")\n",
    "        cursor_obj.callproc(\"status_table_create\")\n",
    "        cursor_obj.close()\n",
    "        connection.commit()\n",
    "    finally:\n",
    "        connection.close()\n",
    "else: # this doesn't work: importing a script into mysql is tricky\n",
    "    print(\"stored procedures need to be compiled in server\") # running the stored procedure codebase script (.sql) from Python is an option\n",
    "    #attempting to run the .sql as scripts\n",
    "    with engine.connect() as conn:\n",
    "        with open(\"/home/candela/Documents/greeneHill/membershipReportsCIVI/github/greeneHill/stored_procedure_create_type_tables.sql\") as file:\n",
    "            query = text(file.read())\n",
    "            conn.execute(query)\n",
    "        with open(\"/home/candela/Documents/greeneHill/membershipReportsCIVI/github/greeneHill/stored_procedure_create_status_table.sql\") as file:\n",
    "            query = text(file.read())\n",
    "            conn.execute(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both key resultsets from the stored procedures verified in db\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "insp = inspect(engine)\n",
    "table_name_list = insp.get_table_names()\n",
    "\n",
    "# two key resultsets from the stored procedures: consolidated_mem_type_temp2 & consolidated_mem_status_temp2\n",
    "if all([i in table_name_list for i in ('consolidated_mem_type_temp2', 'consolidated_mem_status_temp2')]):\n",
    "    print('both key resultsets from the stored procedures verified in db')\n",
    "else:\n",
    "    print('stored procedures did not create the two key resultsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both legacy tables verified in db\n"
     ]
    }
   ],
   "source": [
    "# two key resultsets from the stored procedures: consolidated_mem_type_temp2 & consolidated_mem_status_temp2\n",
    "if all([i in table_name_list for i in ('consolidated_mem_type', 'consolidated_mem_status')]):\n",
    "    print('both legacy tables verified in db')\n",
    "else:\n",
    "    print('legacy tables not in db')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QA options post stored procedure calling:\n",
    "- range of dates covered: new tables should extend **beyond** the legacy prod tables\n",
    "- \\# of total records, ie table size: new tables should have **more** records than legacy tables\n",
    "- analyze a contingency table of status or types: shape or dimension of contingency of new tables should be > or = to legacy\n",
    "\n",
    "The two stored procedures create persisted tables *consolidated_mem_type_temp2* and *consolidated_mem_status_temp2*. These serve as candidate tables to replace the prod tables *consolidated_mem_type* and *consolidated_mem_status*, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min and max values are as expected; you may proceed\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import Table, text, MetaData # a CORE approach\n",
    "from sqlalchemy.sql import select\n",
    "from sqlalchemy.sql import func\n",
    "from collections import namedtuple\n",
    "metadata_obj = MetaData() # a container object\n",
    "#table reflection method to create a table object inferred from a table persisted in the db\n",
    "#ea of the below 4 tables are the results of the stored procedure run in the step above\n",
    "consolidated_mem_type_temp2 = Table(\"consolidated_mem_type_temp2\", metadata_obj, autoload_with=engine) # 'metadata_obj argument purpose is to associate the table to the metadata object\n",
    "consolidated_mem_status_temp2 = Table(\"consolidated_mem_status_temp2\", metadata_obj, autoload_with=engine)\n",
    "#pre-existing (to the calling of the stored procedures) consolidated tables\n",
    "consolidated_mem_type = Table(\"consolidated_mem_type\", metadata_obj, autoload_with=engine)\n",
    "consolidated_mem_status = Table(\"consolidated_mem_status\", metadata_obj, autoload_with=engine)\n",
    "\n",
    "#ensure the tables have data\n",
    "with engine.connect() as conn:\n",
    "    type_new = conn.execute(text(\"SELECT COUNT(*) FROM consolidated_mem_type_temp2\"))\n",
    "    status_new = conn.execute(text(\"SELECT COUNT(*) FROM consolidated_mem_status_temp2\"))\n",
    "    type_legacy = conn.execute(text(\"SELECT COUNT(*) FROM consolidated_mem_type\"))\n",
    "    status_legacy = conn.execute(text(\"SELECT COUNT(*) FROM consolidated_mem_status\"))\n",
    "    \n",
    "\n",
    "table_stats = namedtuple(\"table_stats\",['type_new','status_new','type_legacy','status_legacy'])\n",
    "connect_stats = table_stats(*[i.scalar() for i in (type_new,status_new,type_legacy,status_legacy)])\n",
    "\n",
    "\n",
    "#ensure that replacement tables are longer than legacy\n",
    "if connect_stats.type_new>connect_stats.type_legacy and connect_stats.status_new>connect_stats.status_legacy:\n",
    "    print(\"min and max values are as expected; you may proceed\")\n",
    "else:\n",
    "    print(\"min and max values appear off; stored procedure resultsets should be reviewed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check min and max dates of the 'maxstart' field: expect the min dates of the legacy and replacement tables to be the same; but expect the max date field to be greater for the replacement table\n",
    "with engine.connect() as conn: # Connections instances are typically for CORE and Sessions typical for ORM\n",
    "    #result = a CursorResult object; first() method returns a scalar\n",
    "    min_legacy_type = conn.execute(select(func.min(consolidated_mem_type.c.start_dt).label(\"minstart\"))).first()\n",
    "    max_legacy_type = conn.execute(select(func.max(consolidated_mem_type.c.start_dt).label(\"maxstart\"))).first()\n",
    "    min_replace_type = conn.execute(select(func.min(consolidated_mem_type_temp2.c.start_dt).label(\"maxstart\"))).first()\n",
    "    max_replace_type = conn.execute(select(func.max(consolidated_mem_type_temp2.c.start_dt).label(\"maxstart\"))).first()\n",
    "\n",
    "    min_legacy_status = conn.execute(select(func.min(consolidated_mem_status.c.start_dt).label(\"maxstart\"))).first()\n",
    "    max_legacy_status = conn.execute(select(func.max(consolidated_mem_status.c.start_dt).label(\"maxstart\"))).first()\n",
    "    min_replace_status = conn.execute(select(func.min(consolidated_mem_status_temp2.c.start_dt).label(\"maxstart\"))).first()\n",
    "    max_replace_status = conn.execute(select(func.max(consolidated_mem_status_temp2.c.start_dt).label(\"maxstart\"))).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date relationships between all tables are as expected; you can proceed\n"
     ]
    }
   ],
   "source": [
    "#QA date ranges of the legacy and replacement tables\n",
    "a = min_legacy_type == min_replace_type #start dates of legacy and replacement (NOTE: replacement <> new table)\n",
    "b = max_legacy_type < max_replace_type\n",
    "\n",
    "c = min_legacy_status == min_replace_status\n",
    "d = bool(max_legacy_status < max_replace_status)\n",
    "\n",
    "if all([a,b,c,d]):\n",
    "    print('date relationships between all tables are as expected; you can proceed')\n",
    "else:\n",
    "    print('table dates aren\\'t as expected; review output from stored procedures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO call the stack_job stored procedure <- the final input table to the active accounts study"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
